---
layout: post
title:  "机器学习笔记一"
categories: Machine_learning
tags:  总结 Machine_learning 基础知识
author: zyy
---

* content
{:toc}

本文是我在看西瓜书和机器学习教学视频的总结。




## 机器学习的三步：
1. 定义一组方程（model）
2. 判断方程的好坏
3. 选择最佳的方程

分类和回归是监督学习的代表，而聚类则是无监督学习的代表。

任何一个有效的机器学习算法必有其归纳偏好，否则他将被假设空间中看似在训练集上等效的假设所迷惑，从而无法产生确定的学习结果。
常用的归纳偏好：奥卡姆剃刀：多个假设与观察一致时，选最简单的那个！

没有免费的午餐定理：在所有问题出现机会均等或者所有问题同等重要时，所有的算法的性能的期望相等。但是，现实中并不是所有的问题的重要性或者出现的机会都相等的！

## 模型评估与选择

错误率：分类错误的样本数占样本总数的比例。
精度 = 1 - 错误率

在训练集上的误差：训练误差（经验误差）

在新样本上的误差：泛化误差

过拟合：学习器将训练样本自身的特点当做所有样本都会有的性质，导致泛化性能下降。（学习能力过于强大）

欠拟合： 尚未学好训练样本的一般性质！（学习能力低下）

测试误差，作为泛化误差的近似。测试集应尽可能与训练集互斥。

数据集的训练集和测试集的划分方法：留出法（一刀切两半）、交叉验证法（切成K份，k-1份训练，1份测试，循环k次）、自助法（循环从数据集中取数据，组成训练集，在数据集较小难以划分训练集和测试集时，比较有效）

回归任务的性能度量常用：均方误差！


将样例根据其真实类别和学习器预测类别的组合划分为真正例TP、假正例FP、真反例TN、假反例FN。

查准率：P = TP/(TP+FP)
查全率：R = TP/(TP+FN)
两者一般相互矛盾，只有在简单任务中，才有可能两个值均高！
若一个学习器的P-R曲线可完全包住另一个的P-R曲线，则可断定前者性能优于后者。当两者的P-R曲线相交时，可用P-R曲线覆盖的面积或者P-R曲线平衡点或F1度量结合具体场景来判断两者的优劣。
F1 = (2*P*R)/(P+R) = (2*TP)/(样例总数+TP-TN)
Fb = ((1+b**2)*P*R)/(b**2*P+R)可调节b的值，从而表达对P和R的偏好，b越大，R的影响越大。

ROC曲线与AUC
真正例率：TPR = TP/(TP+FN)
假正例率：FPR = FP/(FP+TN)

若一个学习器的ROC曲线可完全包住另一个的ROC曲线，则可断定前者性能优于后者。当两者的ROC曲线相交时，可用ROC曲线覆盖的面积AUC来比较，面积大的，性能更好。

“偏差-方差分解”是解释学习算法泛化性能的重要工具。

偏差：度量了学习算法的期望预测与真实结果之间的偏离程度，即刻画了学习算法本身的拟合能力。

方差：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响；

噪声：则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。

泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。训练前期，偏差主导泛化错误率；随着训练程度的加深，方差逐渐主导了泛化错误率，此时若学习器学到了数据集本身的特性，则会发生过拟合。



## 线性模型

线性模型（linear model）试图学得一个通过属性的线性组合来进行预测的函数。
f(x) = w*x + b

### 利用线性模型来进行回归学习

基于均方误差最小化来进行模型求解的方法称为：最小二乘法。在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧氏距离之和最小。

求解w和b，使得均方误差期望最小化的过程，称为线性回归模型的最小二乘“参数估计”。通过求偏导为0的方式求解。

当有多个w使得均方误差最小时，由学习器的归纳偏好决定使用哪一个，通常的做法是引入正则化项。

广义线性模型：利用一个单调可微的联系函数实现输入空间到输出空间的非线性函数映射。

### 利用线性模型来解决分类任务

建立广义线性模型：找到一个单调可微函数将分类任务的真实标记y与线性回归模型的预测值联系起来。

对数几率函数：y = 1/(1+e\**(-z))是一种sigmod函数，将z值转化为接近0或1的y值。这一单调可微函数可用于二分类任务。

这一问题的w和b的求解，用极大似然法，进行转化后，求偏导。

### 线性判别分析
将样例进行投影，使得同类型的样例投影点尽可能的接近，不同类型的投影点尽可能的远离，从而解决二分类和多分类问题。

方差：是每个样本与样本均值的差值的平方和取平均。是协方差的一种特殊情况，即两个变量相同的情况。

协方差：用于衡量两个变量的总体误差，是两个变量总体误差的期望。
Cov(x,y) = E[(x - E[x])*(y - E[y])] = E[xy] - E[x]E[y] - E[x]E[y] + E[x]E[y] = E[xy] - E[x]E[y]

如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值时另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值；如果两个变量的变化趋势相反，即其中一个变量大于自身的期望值时另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。

如果X与Y是统计独立的，那么二者之间的协方差就是0，因为两个独立的随机变量满足E[XY]=E[X]E[Y]。
但是，反过来并不成立。即如果X与Y的协方差为0，二者并不一定是统计独立的。
协方差Cov(X,Y)的度量单位是X的协方差乘以Y的协方差。而取决于协方差的相关性，是一个衡量线性独立的无量纲的数。
协方差为0的两个随机变量称为是不相关的。

协方差与方差之间有如下关系：
Cov(X，X)=D(X)
D(X+Y)=D(X)+D(Y)+2Cov(X，Y)
D(X-Y)=D(X)+D(Y)-2Cov(X，Y)

协方差矩阵：
分别为m与n个标量元素的列向量随机变量X与Y，这两个变量之间的协方差定义为m×n矩阵.其中X包含变量X1.X2......Xm，Y包含变量Y1.Y2......Yn，假设X1的期望值为μ1，Y2的期望值为v2，那么在协方差矩阵中（1,2）的元素就是X1和Y2的协方差。

两个向量变量的协方差Cov(X,Y)与Cov(Y,X)互为转置矩阵。

协方差有时也称为是两个随机变量之间“线性独立性”的度量，但是这个含义与线性代数中严格的线性独立性线性独立不同。


### 多分类学习

某些二分类方法可直接推广到多分类，但更多情况下是，基于一些基本策略，利用二分类学习器解决多分类问题。

多分类学习的基本思路是：拆解法，将多分类问题拆解为若干个二分类问题求解。

经典拆分策略：一对一(OvO)、一对其余(OvR)、多对多(MvM)

OvO将N个类别两两配对，产生N(N-1)/2个二分类任务。训练时，将两个类别的样例作为输入，一个作为正例，另一个作为反例，获得一个二分类器。测试时，将新样本交给所有二分类器，得到N(N-1)/2个结果，通过投票的方式，将被预测的最多的类别作为最终结果。

OvR每次将一个类的样例作为正例，其他所有类作为反例，训练N个分类器。测试时，若仅一个分类器预测为正，则划为该类。若有多个预测为正，则选择置信度最大的类别。

OvR比OvO需要训练的分类器少一些，但是每次训练时需要使用全部的样本，而OvO仅需要相关的两类样本，因此在类别很多时，OvO训练时间开销可能更少。测试时训练器多，OvO的测试时间开销也多。两者的性能多数情况下差不多。

MvM每次将若干个类作为正类，其他若干个类作为反类。其中涉及到正、反类的编码构造技术。纠错输出码最常用。在测试时，对于分类器的错误有一定的容忍和修正能力，编码越长纠错能力越强，但训练器的增加，开销也会增加，而且有限类别数的组合数目是有限的，码长超过一定的范围没有意义。

对同等长度的编码，任意两个类别之间的编码距离越远，纠错能力越强。模型的性能还与类别子集的区分难度有关。

### 类别不平衡问题

类别不平衡问题是指：分类任务中不同类别的训练样例数目差别很大的情况。假设一个样本集中有998个反例，2个正例，就算它只会判定为反例，也有998%的准确率，但这样训练出的学习器没有意义。

在多分类问题中，就算原本的各类样本数目相当，在使用OvM，MvM策略后，也有可能导致类别不平衡现象。

解决类别不平衡现象主要有三种方法：
1. 对训练集中的反类样例进行欠采样，即去除一些反例，使正反样例数目接近；
2. 对训练集中的正类样例进行过采样，即增加一些正例，使得正反样例数目接近；
3. 直接基于原始数据集进行学习，但在用训练好的分类器时，对预测结果进行再缩放，称为阈值移动。

欠采样的开销通常远小于过采样，因为训练集小了一些，过采样不能简单的对正样本重复采样，否则会导致严重过拟合，可通过对训练集中的正例进行插值来产生额外的正例。欠采样可能丢失数据集的信息，因此可利用集成学习，将反例划给多个学习器，每个学习器都进行了欠采样，但总体上并没有丢失信息。

阈值移动是将学习器预测的结果，乘以反例数目与正例数目的比值。



